<section xml:id="taylor-series-definition">
  <title>Taylor Series</title>
  <subsection xml:id="analytic-functions">
    <title>Analytic Functions</title>
    <p>
      Once again, consider the geometric series:
      <me>
        f(x) = \sum_{n=0}^\infty x^n = \frac{1}{1-x}
      </me>
    </p>
    <p>
      Unlike most of the power series we've seen so far,
      we actually know the values of the geometric series.
      This series, as a function,
      is the same as the function
      <m>\frac{1}{1-x}</m> on the domain <m>(-1,1)</m>. (The function
      <m>\frac{1}{1-x}</m> is certainly defined on a larger domain,
      but the series is not).
      We can say that the geometric series lets us write
      <m>\frac{1}{1-x}</m> as an infinite series;
      it is the infinite series representation of the function on the domain <m>(-1,1)</m>.
    </p>
    <p>
      The theory of Taylor series generalizes this situation.
      For various functions <m>f(x)</m>,
      we want to a build representation of <m>f(x)</m> as a series.
      This will be a power series which is identical to <m>f(x)</m>,
      at least for part of its domain.
      To find the power series,
      we need to choose a centre point <m>\alpha</m> and find coefficients <m>c_n</m> such that
      <me>
        f(x) = \sum_{n=0}^\infty c_n (x-\alpha)^n
      </me>.
    </p>
    <definition>
      <statement>
        <p>
          A function is called <term>analytic</term>
          at <m>\alpha \in \RR</m> if it can be expressed as a power series centered at <m>\alpha</m> with a non-zero radius of convergence.
          Such a power series is called a
          <term>Taylor series</term>
          representation of the function.
          In the case that <m>\alpha = 0</m>,
          a Taylor series is often called a
          <term>MacLaurin series</term>.
        </p>
      </statement>
    </definition>
    <p>
      We know that power series
      (and therefore all possible Taylor series)
      are <m>C^\infty</m>.
      There is a nice theorem that provides the reverse implication.
    </p>
    <theorem>
      <statement>
        <p>
          A function <m>f</m> is <m>C^\infty</m> at a point
          <m>\alpha \in \RR</m> if and only if there exists <m>R>0</m> such that <m>f</m> is analytic on <m>(\alpha-R,\alpha+R)</m>.
        </p>
      </statement>
    </theorem>
    <p>
      This theorem answers the questions of which functions have Taylor series representations:
      any function which is infinitely differentiable can be expressed as a series,
      but no other functions can be so expressed.
    </p>
  </subsection>
  <subsection xml:id="calculating-coefficients">
    <title>Calculating Coefficients</title>
    <p>
      The previous section defined a class of analytic functions,
      but it didn't tell us how to actually find the series for these functions.
      We get to choose the centre point <m>\alpha</m>,
      so we need to know how to calculate the coefficients <m>c_n</m>.
      Assuming we have a series expression of <m>f(x)</m>,
      let's look at the values of <m>f</m> and its derivatives.
      Then we calculate the values of the derivatives at the centre point <m>\alpha</m>.
      <md>
        <mrow>f(\alpha) \amp  = \sum_{n=0}^\infty c_n (\alpha-\alpha)^n = c_0 + \sum_{n=1}^\infty c_n \cdot 0 = c_0 \implies c_0 = f(\alpha)</mrow>
        <mrow>f^{\prime} (\alpha) \amp  = \sum_{n=1}^\infty c_n n (\alpha-\alpha)^{n-1} = c_1 + \sum_{n=2}^\infty c_n \cdot 0 = c_1 \implies c_1 = f^\prime(\alpha)</mrow>
        <mrow>f^{\prime \prime} (\alpha) \amp  = \sum_{n=2}^\infty c_n n (n-1) (\alpha-\alpha)^{n-2} = 2c_2 + \sum_{n=3}^\infty c_n \cdot 0 = 2c_2 \implies c_2 = \frac{f^{\prime\prime}(\alpha)}{2}</mrow>
        <mrow>f^{(3)} (\alpha) \amp  = \sum_{n=3}^\infty c_n n (n-1) (n-2) (\alpha-\alpha)^{n-3} = 6c_3 + \sum_{n=4}^\infty c_n \cdot 0 = 6c_3 \implies c_3 = \frac{f^{(3)}(\alpha)}{6}</mrow>
        <mrow>f^{(4)} (\alpha) \amp  = \sum_{n=4}^\infty c_n n (n-1) (n-2) (n-3) (\alpha-\alpha)^{n-4} = 24c_4 + \sum_{n=5}^\infty c_n \cdot 0</mrow>
        <mrow>f^{(4)} (\alpha) \amp  = 24c_4 \implies c_4 = \frac{f^{(4)}(\alpha)}{24}</mrow>
        <intertext>We generalize the pattern to write a general expression for the <m>n</m>th coefficient.</intertext>
        <mrow>c_n \amp  = \frac{f^{(n)}(\alpha)}{n!}</mrow>
      </md>
    </p>
    <p>
      Now we have a way to calculate the coefficient in terms of the derivatives of <m>f(x)</m> at the chosen centre point.
      Therefore, to find a series representation of <m>f(x)</m> centered at <m>\alpha</m> (assuming <m>f(x)</m> is analytic at <m>\alpha</m>),
      we use this expression above to calculate the coefficients.
      We summarize this in a proposition.
    </p>
    <proposition>
      <statement>
        <p>
          If <m>f</m> is analytic at <m>\alpha</m>,
          then the Taylor series for <m>f</m> has this form:
          <me>
            f(x) = \sum_{n=0}^\infty \frac{f^{(n)}(\alpha)}{n!} (x-\alpha)^n
          </me>
        </p>
      </statement>
    </proposition>
    <p>
      The expression for the coefficients <m>c_n</m> allows for another important result.
    </p>
    <proposition>
      <statement>
        <p>
          (Uniqueness of Coefficients) Two power series centered at the same point are equal if an only if every coefficient is equal.
        </p>
      </statement>
    </proposition>
    <proof>
      <p>
        Say we have an equation of power series:
        <me>
          \sum_{n=0}^\infty c_n (x-\alpha)^n = \sum_{n=0}^\infty b_n (x-\alpha)^n
        </me>
      </p>
      <p>
        The coefficients are determined by the derivatives.
        But the functions are the same,
        so they must have the same derivatives at <m>\alpha</m>.
        Therefore, both <m>b_n</m> and <m>c_n</m> must be calculated by
        <m>\frac{f^{(n)}(\alpha)}{n!}</m>, hence <m>b_n = c_n</m>.
      </p>
    </proof>
    <p>
      Uniqueness of coefficients is very important for doing algebra with series.
      If two series are equal,
      we can then pass to the equality of each of the coefficients to get explicit equations.
      Curiously, since all the coefficients are determined by the derivatives at the centre point,
      this means that the derivatives at the centre point encode the entire behaviour of the function
      (inside the radius of convergence).
      This is a surprising result,
      since functions can have a wide range of behaviours far away from their centre points.
    </p>
  </subsection>
</section>