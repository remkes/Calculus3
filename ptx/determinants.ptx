<section xml:id="determinants">
  <title>Determinants</title>
  <p>
    Linear transformations are defined by their symmetries:
    they preserve linear subspaces and linear operations.
    We use associated matrices to understand these transformations.
    Matrices are an algebraic description,
    so that questions of transformation can be turned into algebraic problems.
    Now that we have the algebraic description of transformations as matrices,
    we want to investigate what else the matrix can tell us about the transformation.
    In this section, we are asking two questions in particular.
  </p>
  <p>
    First, what does the transformation do to the size of objects?
    I choose the vague word <sq>size</sq> intentionally because we work in various dimensions.
    In one dimension, size is length.
    In two dimensions, size is area.
    In three dimensions, size is volume.
    And in higher dimensions,
    we have some extended notion of volume that fits that dimension;
    we can call this hyper-volume.
    It is important to note that size depends on the ambient dimension.
    A square in <m>\RR^2</m> has some area, some non-zero size.
    But if we have a flat square somewhere in <m>\RR^3</m>,
    it has no volume, therefore no substantial size in that space.
  </p>
  <p>
    Second, what does the transformation do to the orientation of an object?
    Orientating is slightly trickier to understand than size,
    so we will define it for each dimension.
    In <m>\RR</m>, orientation is direction:
    moving in the positive or negative direction along the numberline.
    There are only two directions of movement, so two orientations.
    If we have a transformation of <m>\RR</m>,
    we can ask if it changes or preserves these directions.
    In <m>\RR^2</m>, instead of moving in line,
    we think of moving in closed loops or paths.
    These paths can be clockwise or counter-clockwise.
    Then we can ask if a transformation changes clockwise loops into other clockwise loops or into counter-clockwise loops.
    This gives a notion of orientation in <m>\RR^2</m>.
    In <m>\RR^3</m>,
    orientation relates to the relative position of positive directions.
    The axis system in <m>\RR^3</m> is,
    conventionally, given by a right-hand-rule.
    It we know the <m>x</m> and <m>y</m> directions,
    the right-hand-rule indicates the positive <m>z</m> direction.
    Then we can ask where these three directions go under a transformation and if a right-hand-rule still applies.
    If it does, we preserve the orientation.
    If it doesn't, and a left-hand-rule would work instead,
    the transformation reverses orientation.
    In higher dimension,
    there are other extentions of the notion of orientation.
    In each case, the question is binary:
    a transformation either preserves or reverses orientation..
  </p>
  <definition>
    <statement>
      <p>
        Let <m>M</m> be a square <m>n \times n</m> matrix.
        The <term>determinant</term> of <m>M</m> is a real number,
        written <m>\det M</m>, with two properties.
        Its absolute value <m>|\det M|</m> measures the effect that <m>M</m> has on size
        (length, area, volume, hyper-volume).
        Its sign (positive or negative) measures the effect on orientation;
        if the sign is positive, orientation is preserved,
        and if the sign is negative, orientation is reversed.
      </p>
    </statement>
  </definition>
  <p>
    That definition is all well and good,
    but we need to show that such a thing can be constructed.
    The next section gives an algorithm for building determinants.
  </p>
</section>